{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_coffee_data()\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min pre Normalization: 284.99, 151.32\n",
      "Duration    Max, Min pre Normalization: 15.45, 11.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min pre Normalization: {np.max(X[:, 0]):0.2f}, {np.min(X[:, 0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre Normalization: {np.max(X[:, 1]):0.2f}, {np.min(X[:, 1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of the Data\n",
    "norm_1 = tf.keras.layers.Normalization(axis=-1)\n",
    "# adapt() is used to learn mean and variance from the data\n",
    "norm_1.adapt(X)\n",
    "Xn = norm_1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min Post Normalization: 1.66, -1.69\n",
      "Duration    Max, Min post Normalization: 1.79, -1.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min Post Normalization: {np.max(Xn[:, 0]):0.2f}, {np.min(Xn[:, 0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post Normalization: {np.max(Xn[:, 1]):0.2f}, {np.min(Xn[:, 1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2) (200000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Increase the Current Dataset\n",
    "Xt = np.tile(Xn, (1000, 1))\n",
    "Yt = np.tile(Y, (1000, 1))\n",
    "print(Xt.shape, Yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Model\n",
    "tf.random.set_seed(1234) # To Get Consistent Results\n",
    "model = Sequential(\n",
    "    [\n",
    "        # Specify the Shape of the Input\n",
    "        tf.keras.Input(shape=(2,)),\n",
    "        # Layer 1\n",
    "        Dense(3, activation='sigmoid', name='layer1'),\n",
    "        # Layer 2\n",
    "        Dense(1, activation='sigmoid', name='layer2')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13 (52.00 Byte)\n",
      "Trainable params: 13 (52.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(2, 3):\n",
      " [[ 0.83701587 -0.81385285 -0.00218916]\n",
      " [-0.01571202 -0.40241843 -0.48458833]] \n",
      "b1(3,): [0. 0. 0.]\n",
      "W2(3, 1):\n",
      " [[-0.86867166]\n",
      " [ 0.90148103]\n",
      " [ 0.44986582]] \n",
      "b2(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "# Weights before Training\n",
    "w1, b1 = model.get_layer('layer1').get_weights()\n",
    "w2, b2 = model.get_layer('layer2').get_weights()\n",
    "print(f\"W1{w1.shape}:\\n\", w1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{w2.shape}:\\n\", w2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model with Loss and Optimizer\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 49s 7ms/step - loss: 0.1807\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 46s 7ms/step - loss: 0.0962\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 0.0247\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 38s 6ms/step - loss: 0.0132\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 50s 8ms/step - loss: 0.0087\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 0.0060\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 0.0041\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 33s 5ms/step - loss: 0.0028\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 49s 8ms/step - loss: 0.0020\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 46s 7ms/step - loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x183e9fcabd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model with the Data\n",
    "model.fit(\n",
    "    Xt, Yt,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(2, 3):\n",
      " [[ 14.6055       0.20452468 -11.289298  ]\n",
      " [ 12.111599    10.4002285   -0.31029156]] \n",
      "b1(3,): [  2.0063815  12.537889  -12.139562 ]\n",
      "W2(3, 1):\n",
      " [[-47.93582 ]\n",
      " [ 46.120235]\n",
      " [-56.190105]] \n",
      "b2(1,): [-14.355996]\n"
     ]
    }
   ],
   "source": [
    "# Weights After Training\n",
    "w1, b1 = model.get_layer('layer1').get_weights()\n",
    "w2, b2 = model.get_layer('layer2').get_weights()\n",
    "print(f\"W1{w1.shape}:\\n\", w1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{w2.shape}:\\n\", w2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "predictions = \n",
      " [[9.939981e-01]\n",
      " [9.273377e-08]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # positive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_1(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
